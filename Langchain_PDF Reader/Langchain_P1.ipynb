{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XVfevuN2gcw",
        "outputId": "327e0c6f-bc31-4dbe-d0e5-8f627e3c7239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.9.0\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.45-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
            "Installing collected packages: importlib_metadata, fastavro, backoff, cohere\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.45 fastavro-1.9.3 importlib_metadata-6.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade typing-extensions\n",
        "!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQxQO1nlyw_k",
        "outputId": "5d4a80eb-a42c-413f-ea34-9c81d62f11e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AwcLYLX3HBc2"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "#This support datasets retrieval from Huggingface\n",
        "from datasets import load_dataset\n",
        "\n",
        "#With Cassio, the engine powering the AstraDB integration in Langchain\n",
        "#We will initialize the db connection\n",
        "import cassio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRiiKeIvJHPb",
        "outputId": "38a84091-e7c6-424a-b0c3-7b741694c1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/232.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jO1ukDaHJPYN"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t54a0yVaJ_4m"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:tGQxbwaooAgFbjzejPLCmpXv:30csncsacabckajc94ecb96f6c93bd837bdc1fe58bac2cf9437c02ee9dda245e3d45f\"\n",
        "ASTRA_DB_ID = \"bad87bde-77ea-11e2-ok91-0c656b94bd16\"\n",
        "OPENAI_API_KEY = \"sk-mYjOdk8qbF6mv234PT23hyeo3FJq5MGFATn3xsaRyHIK6mV\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tL8xyzdUoH2Q"
      },
      "outputs": [],
      "source": [
        "pdfreader = PdfReader(\"Introduction to Zynq.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1og27nPxpV4L"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "raw_text = \"\"\n",
        "for i,page in enumerate(pdfreader.pages):\n",
        "  content = page.extract_text()\n",
        "  if content:\n",
        "    raw_text+=content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Sa_XBCNyqksu",
        "outputId": "1b9d9788-1349-4040-e356-096935d0a452"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Introd uction to Zynq:  \\n \\n• Zynq is the new generation o f All-Programmable S ystem -on-Chip (SoC).  \\n• Zynq devices are intended to be flexible and form a comp elling platform for a wide v ariety of \\napplications.  \\n• The defining feature of Zynq is that it combines a dual -core ARM Cortex -A9 processor  with \\ntraditional Field Programmable Gate Array (FPGA) logic fabric . \\n• The ARM Cortex -A9 is an application grade processor, capable  of running full operating systems such \\nas Linux, while the programmable logic is based on  Xilinx 7 -series FPGA architecture . \\n \\n• The architecture is completed by industr y standard AXI interfaces, which provide high bandwidth, \\nlow latency connections between  the two parts of the device .  \\n• This means that the processor and logic can each be used for  what they do best, without the \\noverhead of interfacing between two physically separate  devices.  \\n• Meanwhile, benefits arising from simplifying the system to a single chip include  reductions in \\nphysical size and overall cost.  \\n \\nSystem -on-Chip with Z ynq:  \\n \\n• SoC means that a single silicon chip can be used to implement the functionality of a complete  \\nsystem.  \\n• In the past, the term SoC has usually  referred to an ASIC , which can include digital,  analogue and \\nradio frequency components, together with mixed signal blocks for imple menting ADCs and DACs . \\n• Focus ing on the digital aspect for a moment, an SoC can combine all aspects of a digital  system:  \\no processing, high -speed logic, interfacing, memory, and so on.  \\n \\n• All of these  functions might otherwise be reali zed using physically separate devices and  combined  \\ntogether into a system at the Printed Circuit Board (PCB) level.  \\n• The SoC solution is  \\no lower  cost,  \\no enables faster and more secure data transfers between the various system elements,  \\no has higher overall system speed,  \\no lower power consumption,  \\no smaller physical size, and  \\no better reliability.  \\n \\n• The major disadvantages of ASIC -based SoCs are  \\no development time and cost,   \\no lack of flexibility.  • The NRE effort (and cost) of developing an ASIC  are significant, making this type of SoC suitable only \\nfor high -volume markets where there  is no requirement for future upgrades.  \\n• Representative examples of ASIC -based SoCs are  the integrated processors found in PCs, tablets, and \\nsmartphones; these typically comprise  at least two processor cores, memory, graphics, interfacing, \\nand other functions , and are  manufactured in high volume for products with a limited lifetime.  \\n \\nComparison of a System -on-a-Board a nd System -on-Chip:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The limitations of ASIC SoCs render them incompatible with a significant number of  applications, \\nparticularly where fast time -to-market, flexibility, and upgrade -ability are of  key importance.  \\n• They also constitute a poor solution for low or medium volume markets.  \\n \\n• A mo re flexible solution is  the System -on-Progammable -Chip, a specific flavo r of SoC implemented \\non a programmable, reconfig urable device  (FPGA).  \\n• FPGAs are inherently flexible  devices that can be configured to implement any arbitrary syste m.  \\n• They  can also be reconfigured as often as desired, thus offering a more flexible platform than ASICs \\nfor implementing SoCs.  \\n \\n• Xilinx  markets the device as an ‘All-Programmable SoC ’ (APSoC), which perfectly captures it s \\ncapabilities.  \\n \\n \\n \\n• Below is a high -level model of Zynq  architecture . It comprises of t wo main parts:  \\no Processing System (PS) formed around a dual -core ARM  Cortex -A9 processor, and  \\no Programmable Logic (PL), which is equivalent to that of an  FPGA.  \\no It also contains additional features like integrated memory, a variety of peripherals, and high -\\nspeed  communications interfaces.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The PL section is ideal for implementing high -speed logic, arithmetic,  and data flow  subsystems .  \\n• While the PS supports software routines and/or operating systems, meaning  that the overall \\nfunctionality of any designed system can be appropriately partitioned  between hardware and \\nsoftware.  \\n• Links between the PL and PS are made using industry  standard Advanced eXtensible Interface (AXI) \\nconnections . \\n \\nSimple Anatomy of an Embedded So C: \\n \\n• The model of the hardware system is shown below which comprises of:  \\no a processor , \\no memories,  \\no periph erals , and  \\no buses connecting the various elem ents together.  \\n \\n \\n \\n \\n \\n• The processor  can be regarded as the central element of the hardware system.  \\no The software system (a software ‘stack ’) is run on the processor . \\no It compris es applications  (usually based on an OS), and a lower layer of software \\nfunction ality for interfacing with the hardware system.  \\n \\n• Communication between system elements  takes place via interconnections .  \\no These may be in the style of direct, point -to-point links, or  buses serving multiple \\ncomponents.  \\no In the latter case, a protocol is required to manage  access to the bus.  \\no Although a single bus with connected peripherals is shown in  the figure , a processor may \\nserve several connected buses.  \\n \\n• Peripherals  are functional components residing away from the processor, and in general  these \\nperform one of three functions:  \\no coprocessors — elements that supplement the  primary processor, usually optimi zed for a \\ncertain task , \\no cores for interacting with  external interfaces, e.g. connecting to LEDs and switches, etc., and  \\no additional  memory elements.  \\no Peripherals are  discrete functional blocks that can be designed, tested , and integrated into a \\nsystem, and also ‘packaged ’ for later reuse.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The figure provides a view of the hardware system  mapped to the  Zynq device . \\n• The PS has a fixed architecture and hosts the  processor and system memory . \\n• The PL is completely flexible, giving the designer a  ‘blank canvas ’ to create custom peripherals, or to \\nreuse standard ones.  \\n• The interconnec tions are implemented via AXI interfaces linking the PS and PL.  \\n• The software system can also be seen on the left -hand side , the software  is hosted on the processor, \\nwhich here is the ARM Cortex -A9, residing within the Zynq PS.  \\nDesign Re use: \\n \\n• There  are particular advantages to undertaking the design of a system on a platform such as an FPGA \\nor Zynq device, which make the process more straightforward.  \\n• The underlying PL hardware is  structured, and its performance characteristics are well known and  \\nintegrated into the  software development tools.  \\n• Moreover, given this stable, common development platform,  there is huge scope for design reuse.  \\n \\n• Intellectual Property (IP) functional blocks (corre sponding to the peripheral components ) can be \\nsourced from Xilin x libraries , reused from previous projects, or brought in  from third parties or open -\\nsource  repositories, before being integrated together to form the  system design.  \\n \\n• Zynq is an SoC, and a wide variety of standard IP is available, meaning that there is no  need to \\nredesign these components . \\n• By raising the abstraction level in this way, and reusing  components , development can be  \\naccelerated , and costs can be lowered.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRaising the Abs tract ion Level:  \\n \\n• The design processes can b e accele rated i f the designer can effectively create  systems with a lower \\nrequirement for explicit design input . \\n• In terms of FPGA and Zynq design, advances in High Level Synthesis (HLS) mean that  designers can \\ncreate system components by specifying them using less detail than traditional  RTL methods . \\n• They can instead rely upon the design tools to  infer logic and optimi ze where possible, in accordance \\nwith user -supplied direction.  \\n• The development tools  must therefore  be robust and  produce repeatable and reliable designs.  \\n• To meet this need, Xilinx has introduced the  Vivado HLS tool, a high -level  synthesis development tool \\nwhich specifically targets Xilinx  devices.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSoC Design Flow:  \\n \\n• The basic  and advanced  stages in a  SoC design  flow (as applied to Zynq ) is sho wn below:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The first stage is to define the desired behavio rs of  the system, i.e. requirem ents specification .  \\no This is  depicted as the starting point at the top of the diagram . \\no It forms the basis of the system  design that is subsequently developed.  \\n \\n• The Zynq architecture combines an ARM processor  (for software elements of the  system) with FPGA \\nfabric (predominantly for  hardware elements of the system ).  \\no A key element of the system design stage  is therefore to partition the intended functionality \\nappropriately between software and  hardware .  \\no And to define the interfaces between the two sections.  \\n \\n• Having partitioned the system, software and hardware development  can then progress in  parallel, \\nto a large extent.  \\no In terms of hardware development , the task is to identify the  necessary functional blocks to \\nachieve the design, and to assemble them through  some combination of design reuse and \\nnew IP development and  make appropriate  connections between the blocks.  \\n \\no The software development aspect of the project can be realized  through developing custom \\ncode or by reusing pre -existing software.  \\n \\no Verification of both  software and hardware will be required, and this forms an integral and \\nimportant part of  the process.  \\n \\n• In system  integration and testing sta ge, the hardware and software elements of the system must be \\nintegrated according  to the interfaces defined at the specification stage .  \\no And further ‘whole system ’ testing  is carried out . \\n \\nThe Zynq Device:  \\n \\n• The PS and the  PL parts can be used independently or together . \\n• In fact, the power circuitry is configured with separate  domains for each, enabling either the PS or PL \\nto be powered down if not in use.  \\n• However,  the most compelling use model for Zynq is when both of its constituent parts are used in  \\nconjunction . \\n \\n• PS: Processing system, hard silicon cor e \\no Dual ARM Cortex -A9 processor . \\no Multiple peripherals . \\n \\n• PL: Programmable logic  \\no Shares the same 7 series programmable logic as  \\n▪ Artix -based devices: Z -7010 and Z -7020 . \\n▪ Kintex -based devices: Z -7030 and Z -7045 . • How were FPGAs used in the past:  \\n \\n \\n \\n \\n \\n \\n \\n \\nThe Processing S ystem:  \\n \\n• All Zynq devices have the same basic architecture, and all of them contain  a dual -core ARM Cortex -\\nA9 processor  as the PS.  \\n• This is a ‘hard ’ processor i.e., it exists as a dedicated and optimi zed silicon element on the device.  \\n \\n• For comparison purposes, the alternative to a hard processor is a ‘soft’ processor like the  Xilinx \\nMicroBlaze, which is formed by combining elements of the programmable logic  fabric .  \\n• The implementation of a soft processor is therefore the equivalent of any other  IP block deployed in \\nthe logic fabric of an FPGA.  \\n• In general, the advantage of soft  processors  is that the number and precise implementation of \\nprocessor instances is flexible.  \\n \\n• On the other hand, hard processors can achieve considerably higher performance . \\n• One or more MicroBlaze soft processors can be used within the PL  portion of the Zynq, to operate in \\nconjunction with the ARM processor.  \\n• The MicroBlaze  instances may have, for example,  \\no the role of co ordinating specific low -level functions  within the system , \\no or less demanding tasks which can be delegated away from the main ARM  Cortex -A9 \\nprocessors to enhance overall performance.  \\n \\n• In other words, the presence of the  ARM processor in the system does not prevent  the use of soft \\nprocessors .  \\no Many applications may benefit from employing a processing model  which uses  both types.  \\n \\n• The figure b elow  confirms the positions of the ARM and MicroBlaze processors on the Zynq  device; \\nthe ARM as a dedicated resource, and the MicroBlaze located in the logic fabric.  \\n \\n \\n \\n \\n• The Zynq PS encompasses not just the ARM processor, but a  set of associated processing \\nresources /com ponent s: \\no Application Processing Unit (APU),  \\no I/O peripheral interfaces,  \\n▪ Multiplexed I/ O (MIO)  \\n▪ Extended Multiplexed I/O (EM IO)  \\no Cache memory,  \\no On-Chip memory,  \\no Memory interfaces,  \\no PS interconnect,  \\no Clock, DMA, Timers,  \\no General Interrupt Controller (GIC) , \\no Debug C ontroller: ARM CoreSight   \\n \\n• A block diagram showing the architecture of the PS is shown in  where the APU is highlighted.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nApplication Proc essing Unit (APU):  \\n• A simplified block diagram of the APU is shown .  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The APU is primarily  comprised of two ARM processing cores, each with associated computational \\nunits:  \\no a NEONTM Media Processing Engine (MPE) and Floating -Point  Unit (FPU) ,  \\no a Memory  Management Unit (MMU) , and  \\no a Level 1 cache memory (in two sections for instructions  and data).  \\n \\n• The APU also contains a Level 2 cache memory, and a further On -Chip Memory  (OCM).  \\n• Finally, a Snoop Control Unit (SCU) forms a bridge between the ARM cores and  the Level 2 cache and \\nOCM memories . \\no This unit also has some responsibility for interfacing  with the PL . \\n \\n• The ARM Cortex -A9 can operate at up to 1GHz .  \\n• Each of the two cores has separate Level 1  caches for  data and instructions, both of which are 32KB ; \\nas in the general case, this allows for  local  storage of frequently required data and instructions for \\nfast access times and optimal  processor performance.  \\n• The two cores additionally share a larger Level 2  cache of 512KB  for instructions and data, and there \\nis a further 256KB of on -chip memory  within the APU.  \\n• The primary role of the MMU  is to translate between virtual and physical addresses . \\n \\n• The Snoop Control Unit  undertakes several tasks relating to interfacing between the  processors and \\nLevel 1 and 2 cache memories  (‘snooping ’ is one of several ways  for ensuring cache  coherency ).  \\n• The SCU is  responsible for maintaining memory coherency between the  processor data cache \\nmemories, which are marked as L1(D) , and the shared  Level 2 cache memory.  \\n• It also initiates and controls access to the Level 2 cache, arbitrating  between requests from the two \\ncores where necessary .  \\n \\n• Timers and an interrupt controller are further functional blocks  located in the APU . \\n \\n• As additional functionality to the main ARM processor, the NEON engine  provides  SIMD  facilities to \\nenable strategic acceleration of media  and DSP type algorithms .  \\n• NEON instructions are an extension to the standard ARM  instruction set, and can either be used \\nexplicitly, or by ensuring that the C code follows an  expected form and thus allows NEON operations \\nto be inferred by the compiler .  \\n \\n• As the SIMD term suggests, the NEON engine can accept multiple sets of input vectors, upon  which \\nthe same operation is performed simultaneously to provide a corresponding set of  output vectors.  \\n• This style of computation caters well to applications like \\no image and video  processing, which operate on a large number of data samples (pixels) \\nsimultaneously, and   \\no inherently parallel, generic signal processing functions such as FIR filters and FFTs . \\n \\n• The computation of the NEON engine is depicted in the figure below .  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• There are two input  registers, A and B, each of which contain a set of N individual input vectors.  \\n• A single  defined operation  is performed between the N sets of input vectors to produce a \\ncorre sponding set of output vectors which are written to the output register.  \\n• The size of the  vectors can vary, as can the number of vectors comprising each register . \\n• The important  feature is that each ‘lane ’ produces results arising from the same operation, which is  \\nperformed on several different sets of inputs at the same time , hence the term SIMD.  \\n \\n• NEON supports a variety of data types including signed and unsigned integers, single  precision \\nfloating point, and half -precision floating point; however, double precision is not  supported .  \\n• The FPU (which does not possess SIMD capabilities) is  required if double precision computation is \\nneeded.  \\n \\n• In addition to NEON, there are also extensions for the FPU referred to as ‘Floating Point Extensions ’, \\nor sometimes ‘VFP Extensions ’ (Vecto r Floating Point) for historical reasons.  \\n• The unit provides hardware acceleration of floating -point operations . \\nProcessing S ystem Extern al Interfaces:  \\n \\nThe Zynq PS features a variety of interfaces,  \\nboth between the PS and PL, and  \\nbetween  the PS and external components .  \\n \\n \\n \\n \\n \\n• Communication between the PS and external interfaces is achieved primarily via the  Multiplexed \\nInput/Output (MIO) , which provides 54 pins of flexible connectivity, meaning  that the mapping \\nbetween peripherals and pins can be defined as required.  \\n• Certain connec tions can also be made via the Extended MIO (EMIO) , which is not a direct path from \\nthe PS to external connections, but instead passes through and shares the I/O resources of the  PL.  \\n \\n• The EMIO can be used  when extension beyond 54 pins is required, or as a method of int erfacing the \\nPS with an I P block implemented in the PL.  \\n• The available I/O includes standard communications interfaces, and GPIO  which can be used for a \\nvariety of purposes including simple  buttons, switches, and LEDs.  \\n• The complete set of I/O peripheral interfaces is reviewed in  the t able below, there are two instances \\nof each type of communications interface.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPS Compo nents:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nProg rammable Logi c: \\n \\n• The programmable logic of t he Z ynq architecture is based on the Artix -7 and Kintex -7 FPGA fabric . \\n \\nThe Logic Fabric:  \\n \\n• The PL is predominantly composed of general -purpose FPGA logic fabric,  which is composed of slices \\nand CLBs , and there are also Input/ Output Blocks (IOBs) for interfacing.  \\n• Configurable Logic Block (CLB) : CLBs are small, regular groupings of logic  elements that are laid out \\nin a two -dimensional array on the PL . \\no They are  connected  to other similar resources via programmable interconnects.  \\no Each CLB is positioned  next to a switch matrix and contains two logic slices . \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• Slice : A sub -unit within the CLB, which contains resources for implementing  combinatorial and \\nsequential logic circuits.  \\no Zynq slices  are composed of 4 Lookup Tables, 8 Flip -Flops, and other logic.  \\n \\n• Lookup Table (LUT) : A flexible resource capable of implementing  \\no a logic  function of up to six inputs ,  \\no a small Read Only Memory (ROM) ,  \\no a small  Random Access Memory (RAM) , or  \\no a shift register.  \\no LUTs can be combined  together to form larger logic functions, memories, or shift registers, as \\nrequired.  \\n \\n• Flip-flop (FF) : A sequential circuit element implementing a 1 -bit register, with  reset functionality.  \\no One of the FFs can optionally be used to implement a latch.  \\n \\n• Switch Matrix : A switch matrix sits next to each CLB, and provides a flexible  routing facility for \\nmaking connection s \\no between elements within a CLB  and  \\no from one CLB to other resources on the PL.  \\n \\n• Carry logic : Arithmetic circuits require intermediate signals to be propagated  between adjacent \\nslices, and this is achieved via carry logic.  \\no It comprises a chain of routes and multiplexers to link slices in a vertical column.  \\n \\n• Input /Output Blocks (IOBs) : IOBs are resources that provide interfacing betwee n the PL logic \\nresources, and the physical device ‘pads ’ used to connect to external  circuitry.  \\no Each IOB can handle a 1 -bit input or output signal.  \\no IOBs are usually  located around the perimeter of the device.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The Xilinx tools  automatically infer the required LUTs, FFs, IOBs etc. from the design, and  map s them \\naccordingly.  \\n \\nSpecial Resources: DSP48E1s and BRAMs  \\n \\n• In addition to the general fabric, there are two special purpose components: B RAMs for dense \\nmemory requirements; and DSP48E1 slices for high -speed arithmetic.   \\n• Both of these resources are integrated into the logic array in a column arrangement,  embedded into \\nthe fabric logic . \\n• They are normally in close proximity to each other (the reason being  that intensive computation  – \\nDSP and storage of data in memory – BRAM are often closely associated  operations).  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The B RAMs in the Zynq -7000 are equivalent to those on Xilinx 7 series FPGAs,  and they can \\nimplement RAM, ROM, FIF O buffers, while also supporting Error Correction Coding  (ECC) . \\n• Each B RAM can store up to 36Kb  of information, and may be configured either as  one 36Kb  RAM, or \\ntwo independent 18Kb RAMs .  \\no The default word size is 18 bits, and in  this configuration each RAM comprises 2048 memory \\nelements. (2 x 2^10 = 2048)  \\no The RAM can also be  ‘reshaped ’ such that it contains more, smaller elements (for example \\n4096 elements x 9 bits,  or 8192 x 4 bits), or alternatively, fewer, longer elements (e.g. 1024 \\nelements x 36 bits, 512 x  72 bits).  \\no Larger capacity memories can be formed by combining two or more Block RAMs  together.  \\n \\n• Using a B RAM means that a large amount of data can be stored in a small physical  space on the \\ndevice, within a dedicated and optimi zed memory element . \\n• The alternative is  Distributed RAM, which is constructed from the LUTs within the logic fabric.  \\n• A significant  number of LUTs (spanned over a larger area) are required to form a memory of \\ncomparable  size to a B RAM, and the resulting implementation suffers from restricted timing  \\nperformance due to the increased logic and routing delays.  \\n• On the other hand, it is often  advantageous  to implement small memories using Distributed RAM, \\nboth for resource  efficiency, and because their placement is more flexible . \\no Distributed memories can be  located close to the components that interact with them, \\nwhich can result in fast timing  performance too .  \\n• BRAMs can normally be clocked at the highest clock frequency  supported by the device.  \\n \\n• The LUTs in the logic fabric can be used to implement arithmetic operators of any  arbitrary length \\nbut are most suitable for arithmetic operators with short word lengths . \\no Arithmetic circuits for long word  lengths can have a large footprint in slice logic, with  \\nplacement and routing factors resulting in sub -optimal clock frequencies .  \\n \\n• DSP48E1s  are specialist slices for implementing high -speed arithmetic on signals with medium to \\nlong  arithmetic word  lengths.  \\n• They are dedicated silicon resources, and primarily comprise a  pre-adder/subtractor, multiplier, and \\npost -adder/subtractor with logic unit .  \\n \\n \\n \\n \\n \\n \\n \\n \\n• DSP48E1 makes use of multiplexing circuitry to allow  flexible usage of registers, and to  support \\ndynamic alteration of the computation (i.e. the function can be changed on a cycle -by-cycle basis as \\nrequired).  \\n• Various computations are possible, involving one, two or all of  these arithmetic operators, and these \\nare selected via an OPMODE input  that configures  the internal multiplexers and determines the \\narithmetic  functionality implemented.  \\no Notice that the inputs are labelled A, B, C, and D, and that the  output is labelled P .  \\no The unit can compute the functions P = (A+D)*B, or P = P ’ + C, or in  fact many others.  \\no It is also capable of SIMD processing, implementing 2 or 4 shorte r \\naddition/subtraction/accumulation operations of 24 or 12 bits, respectively.  \\n \\n• The post -adder  has additional capabilities as a logic unit.   \\n• When used in logic mode, it can perform logical functions instead of arithmetic, and  supports all of \\nthe fundamental Boolean  operations: bit -wise NOT, AND, OR, NAND,  NOR , XOR, and XNOR.  \\n \\n• It is also worth mentioning the pattern detector  which adds the capability to detect overflow, \\nperform rounding according to a  selection of schemes  and undertake other related functions.  \\n \\n• The standard arithmetic word  lengths marked on the figure  are adequate for most  requirements, but \\nthey can also be extended by combining multiple DSP48E1s, if needed.  \\n• Complex arithmetic can be undertaken, again by combining DSP48E1s, and the  word  lengths are also \\nsuitable for implementing floating -point arithmetic.  \\n \\n• Together with the  advantage of high frequency operation (just like B RAMs, DSP48E1s can be clocked \\nat the maximum clock frequency of the device) and low power consumption, these DSP48E1  slices \\nare attractive for implementing computationally demanding arithmetic circuits.  \\n \\n• As a result of these properties, DSP48E1s are suited to a variety of applications in signal  processing \\nand beyond.  \\no One of their most compelling uses is to implement symmetric  form F IR filters , which are \\ncommonly used in DSP and digital  communications.  \\no The pre -adder ensures that each DSP48E1 can implement two filter taps,  and entire filters \\ncan be formed by cascading DSP48E1s together, without the requirement  to utilize  any logic \\nfrom the general fabric.  \\no This provides a high performance, highly  efficient implementation for one of the \\nfundamentally important computations in DSP .  \\n \\n• When designing with Zynq, it makes sense to identify deterministic, computationally  parallel \\nfunctions and implement them in the PL section of the device, specifically  targeting DSP and B RAM \\nresources where possible.  \\n• In this way, the PL can be used to  accelerate algorithms residing in the PS.  \\no There are many conceivable examples where the  availability of PL directly adjacent to the \\nprocessor, and the opportunity to allocate certain  system functions to the PL, can bring \\nsignificant benefits to the overall system implemen tation.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n PS – PL Interfaces:  \\n \\n• The key enabler in the integration of PS and PL  is the set of highly specified  AXI interconnects and \\ninterfaces forming the bridge between the two parts.  \\n• There are also  some other types of connections between the PS and PL, in particular EMIO.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe AXI Standards:  \\n \\n \\n \\n \\n \\n \\n \\n \\n• AXI stands for Advanced eXtensible Interface, and the current version is AXI4, which is  part of the \\nARM AMBA ® 3.0 open standard.  \\n• Many devices and IP blocks produced by third  party manufacturers and developers are based on this \\nstandard.  \\n \\n• The AMBA standard was originally developed by ARM for use in microcontrollers, with  the first \\nversion being released in 1996.  \\n• Since then, the standard has been revised and  extended, and it is now described by ARM as “the de \\nfacto standard for on -chip communi cation ”.  \\n• The focus is now on System -on-Chip, including SoCs based on FPGAs or, in  the case of Zynq, a device \\nwhich includes FPGA fabric.  \\n• Xilinx contributed strongly  to defining AXI4 as an optimal interconnect technology for use within \\nFPGA architecture s. \\n• AXI buses can be used flexibly, and in the general sense are used to connect the processor(s)  and \\nother IP blocks in an embedded system.  \\n• There are three flavo rs of AXI4, each  of which represents a different bus protocol . \\n• The cho ice of AXI bus protocol for a particular connection depends on the desired properties of that \\nconnection.  \\n \\n• AXI4 [2] : For memory -mapped links and  providing the highest performance: an  address is supplied \\nfollowed by a data burst transfer of up to 256 data words (or ‘data  beats ’). \\n \\n• AXI4 -Lite [2] : A simplified link supporting only one data transfer per connection  (no bursts).  \\no It is also memory -mapped: in this case an address and single  data word are transferred.  \\n \\n• AXI4 -Stream [1] : For high -speed streaming data, supporting burst transfers of  unrestricted size.  \\no There is no address mechanism; this bus type is best suited to  direct data flow between \\nsource and destination (non -memory mapped) . \\n \\n• If a protocol is memory mapped , an address is specified within the  transaction issued by the master \\n(read or write), which corresponds to an address in the  system memory space.  \\no In the case of AXI4 -Lite, which supports a single data transfer per  transaction, data is then \\nwritten to, or read from, the specified address .  \\no In the case of AXI4  bursts, the address specified is for the first data word to be transferred, \\nand the slave must  then calculate the addresses for the data words that follow.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAXI Interconne cts and Interfaces:  \\n \\n• The primary interface between the PS and PL is via a set of nine AXI interfaces, each of  which is \\ncomposed of multiple channels.  \\n• These make dedicated connections between the  PL, and interconnects within the PS . \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• Interconnect : An interconnect is effectively a switch which manages and directs  traffic between \\nattached AXI interfaces.  \\no There are several interconnects within the  PS, some which are directly interfaced to the PL , \\nand others which  are for internal use only.  \\no The connections between these interconnects are also  formed using AXI interfaces.  \\n \\n• Interface : A point -to-point connection for passing data, addresses, and hand -shaking signals \\nbetween master and slave clients within the system.  \\n \\n• Note from the diagram that all of the interfaces are specifically connected to AXI inter connects \\nresiding within the PS, with the exception of the ACP interface, which is  connected directly to the \\nSnoop Control Unit inside the APU.  \\n \\n• Internally to the PS, AXI interfaces are used within both the ARM APU  (making connections between \\nthe processing cores and SCU, cache memory and OCM),  and more generally to connect the various \\ninterconnects within the PS.  \\n \\n• These connections  are in addition to those at the PS -PL boundary.  \\n• In particular, the three interconnects (the Memory, Master , and Slave Interconnects) are internally \\nconnected to the  Central Interconnect . \\n \\n• The t able below  provides a summary of the interfaces .  \\n• A short description of each interface is given, and the master and slave are indicated (in  accordance \\nwith convention, the master is in control of the bus, and initiates transactions,  while the slave \\nresponds).  \\n• The interface naming convention (as in the left -hand  column ) is to indicate the role of the PS, i.e. \\n“M” is the first letter where the PS  is the master, and “S” is the first letter where the PS is the slave.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• General Purpose AXI : A 32 -bit data bus, which is suitable for low and medium  rate communications \\nbetween the PL and PS.  \\no The interface is direct and does not  include buffering.  \\no There are four general purpose interfaces in total: the PS is the  master of two, and the PL is \\nthe master of the other two.  \\n \\n• Accelerator Coherency Port : A single asynchronous connection between the PL  and the SCU within \\nthe APU, with a bus width of 64 bits.  \\no This port is used to achieve  coherency between the APU caches and elements within the PL.  \\no The PL is the  master.  \\n \\n• High Performance Ports : The four high performance AXI interfaces include FIFO  buffers to \\naccommodate “bursty ” read and write behavio r, and support high -rate communications between \\nthe PL and memory elements in the PS.  \\no The data width is  either 32 or 64 bits, and the PL is the master of all four interfaces.  \\n \\n• Each bus is made up of a collection of signals, and transactions on these buses take place  in \\naccordance with the defined bus standard, AXI4 . \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0928A9Lq0Z4",
        "outputId": "a015752b-0705-46e5-f4d2-00c1c04496d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for bad87bde-77ea-47e0-ac21-0c656b94ac16-us-east1.db.astra.datastax.com:29042:167a44d6-12ed-4032-8521-e99be7a3e0f9. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for bad87bde-77ea-47e0-ac21-0c656b94ac16-us-east1.db.astra.datastax.com:29042:167a44d6-12ed-4032-8521-e99be7a3e0f9. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(133706503166928) bad87bde-77ea-47e0-ac21-0c656b94ac16-us-east1.db.astra.datastax.com:29042:167a44d6-12ed-4032-8521-e99be7a3e0f9> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for bad87bde-77ea-47e0-ac21-0c656b94ac16-us-east1.db.astra.datastax.com:29042:167a44d6-12ed-4032-8521-e99be7a3e0f9. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN,database_id=ASTRA_DB_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vxrJlEvrMqq",
        "outputId": "6218b18c-81b5-450e-a9ad-ce9e88fc2cb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HCdeixQfyuXY"
      },
      "outputs": [],
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name='qa_mini_demo',\n",
        "    session=None,\n",
        "    keyspace=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xys-SNDtzUZm"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swwEK1UR4lUp",
        "outputId": "84d14b9e-68a5-4fc6-8508-f0ace3e91931"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Introd uction to Zynq:  \\n \\n• Zynq is the new generation o f All-Programmable S ystem -on-Chip (SoC).  \\n• Zynq devices are intended to be flexible and form a comp elling platform for a wide v ariety of \\napplications.  \\n• The defining feature of Zynq is that it combines a dual -core ARM Cortex -A9 processor  with \\ntraditional Field Programmable Gate Array (FPGA) logic fabric . \\n• The ARM Cortex -A9 is an application grade processor, capable  of running full operating systems such \\nas Linux, while the programmable logic is based on  Xilinx 7 -series FPGA architecture . \\n \\n• The architecture is completed by industr y standard AXI interfaces, which provide high bandwidth, \\nlow latency connections between  the two parts of the device .',\n",
              " '• The architecture is completed by industr y standard AXI interfaces, which provide high bandwidth, \\nlow latency connections between  the two parts of the device .  \\n• This means that the processor and logic can each be used for  what they do best, without the \\noverhead of interfacing between two physically separate  devices.  \\n• Meanwhile, benefits arising from simplifying the system to a single chip include  reductions in \\nphysical size and overall cost.  \\n \\nSystem -on-Chip with Z ynq:  \\n \\n• SoC means that a single silicon chip can be used to implement the functionality of a complete  \\nsystem.  \\n• In the past, the term SoC has usually  referred to an ASIC , which can include digital,  analogue and',\n",
              " 'system.  \\n• In the past, the term SoC has usually  referred to an ASIC , which can include digital,  analogue and \\nradio frequency components, together with mixed signal blocks for imple menting ADCs and DACs . \\n• Focus ing on the digital aspect for a moment, an SoC can combine all aspects of a digital  system:  \\no processing, high -speed logic, interfacing, memory, and so on.  \\n \\n• All of these  functions might otherwise be reali zed using physically separate devices and  combined  \\ntogether into a system at the Printed Circuit Board (PCB) level.  \\n• The SoC solution is  \\no lower  cost,  \\no enables faster and more secure data transfers between the various system elements,  \\no has higher overall system speed,  \\no lower power consumption,  \\no smaller physical size, and',\n",
              " 'o lower  cost,  \\no enables faster and more secure data transfers between the various system elements,  \\no has higher overall system speed,  \\no lower power consumption,  \\no smaller physical size, and  \\no better reliability.  \\n \\n• The major disadvantages of ASIC -based SoCs are  \\no development time and cost,   \\no lack of flexibility.  • The NRE effort (and cost) of developing an ASIC  are significant, making this type of SoC suitable only \\nfor high -volume markets where there  is no requirement for future upgrades.  \\n• Representative examples of ASIC -based SoCs are  the integrated processors found in PCs, tablets, and \\nsmartphones; these typically comprise  at least two processor cores, memory, graphics, interfacing,',\n",
              " 'smartphones; these typically comprise  at least two processor cores, memory, graphics, interfacing, \\nand other functions , and are  manufactured in high volume for products with a limited lifetime.  \\n \\nComparison of a System -on-a-Board a nd System -on-Chip:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The limitations of ASIC SoCs render them incompatible with a significant number of  applications, \\nparticularly where fast time -to-market, flexibility, and upgrade -ability are of  key importance.  \\n• They also constitute a poor solution for low or medium volume markets.  \\n \\n• A mo re flexible solution is  the System -on-Progammable -Chip, a specific flavo r of SoC implemented \\non a programmable, reconfig urable device  (FPGA).',\n",
              " '• A mo re flexible solution is  the System -on-Progammable -Chip, a specific flavo r of SoC implemented \\non a programmable, reconfig urable device  (FPGA).  \\n• FPGAs are inherently flexible  devices that can be configured to implement any arbitrary syste m.  \\n• They  can also be reconfigured as often as desired, thus offering a more flexible platform than ASICs \\nfor implementing SoCs.  \\n \\n• Xilinx  markets the device as an ‘All-Programmable SoC ’ (APSoC), which perfectly captures it s \\ncapabilities.  \\n \\n \\n \\n• Below is a high -level model of Zynq  architecture . It comprises of t wo main parts:  \\no Processing System (PS) formed around a dual -core ARM  Cortex -A9 processor, and  \\no Programmable Logic (PL), which is equivalent to that of an  FPGA.',\n",
              " 'o Processing System (PS) formed around a dual -core ARM  Cortex -A9 processor, and  \\no Programmable Logic (PL), which is equivalent to that of an  FPGA.  \\no It also contains additional features like integrated memory, a variety of peripherals, and high -\\nspeed  communications interfaces.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The PL section is ideal for implementing high -speed logic, arithmetic,  and data flow  subsystems .  \\n• While the PS supports software routines and/or operating systems, meaning  that the overall \\nfunctionality of any designed system can be appropriately partitioned  between hardware and \\nsoftware.  \\n• Links between the PL and PS are made using industry  standard Advanced eXtensible Interface (AXI) \\nconnections . \\n \\nSimple Anatomy of an Embedded So C:',\n",
              " 'software.  \\n• Links between the PL and PS are made using industry  standard Advanced eXtensible Interface (AXI) \\nconnections . \\n \\nSimple Anatomy of an Embedded So C: \\n \\n• The model of the hardware system is shown below which comprises of:  \\no a processor , \\no memories,  \\no periph erals , and  \\no buses connecting the various elem ents together.  \\n \\n \\n \\n \\n \\n• The processor  can be regarded as the central element of the hardware system.  \\no The software system (a software ‘stack ’) is run on the processor . \\no It compris es applications  (usually based on an OS), and a lower layer of software \\nfunction ality for interfacing with the hardware system.  \\n \\n• Communication between system elements  takes place via interconnections .',\n",
              " 'function ality for interfacing with the hardware system.  \\n \\n• Communication between system elements  takes place via interconnections .  \\no These may be in the style of direct, point -to-point links, or  buses serving multiple \\ncomponents.  \\no In the latter case, a protocol is required to manage  access to the bus.  \\no Although a single bus with connected peripherals is shown in  the figure , a processor may \\nserve several connected buses.  \\n \\n• Peripherals  are functional components residing away from the processor, and in general  these \\nperform one of three functions:  \\no coprocessors — elements that supplement the  primary processor, usually optimi zed for a \\ncertain task , \\no cores for interacting with  external interfaces, e.g. connecting to LEDs and switches, etc., and',\n",
              " 'certain task , \\no cores for interacting with  external interfaces, e.g. connecting to LEDs and switches, etc., and  \\no additional  memory elements.  \\no Peripherals are  discrete functional blocks that can be designed, tested , and integrated into a \\nsystem, and also ‘packaged ’ for later reuse.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The figure provides a view of the hardware system  mapped to the  Zynq device . \\n• The PS has a fixed architecture and hosts the  processor and system memory . \\n• The PL is completely flexible, giving the designer a  ‘blank canvas ’ to create custom peripherals, or to \\nreuse standard ones.  \\n• The interconnec tions are implemented via AXI interfaces linking the PS and PL.',\n",
              " 'reuse standard ones.  \\n• The interconnec tions are implemented via AXI interfaces linking the PS and PL.  \\n• The software system can also be seen on the left -hand side , the software  is hosted on the processor, \\nwhich here is the ARM Cortex -A9, residing within the Zynq PS.  \\nDesign Re use: \\n \\n• There  are particular advantages to undertaking the design of a system on a platform such as an FPGA \\nor Zynq device, which make the process more straightforward.  \\n• The underlying PL hardware is  structured, and its performance characteristics are well known and  \\nintegrated into the  software development tools.  \\n• Moreover, given this stable, common development platform,  there is huge scope for design reuse.',\n",
              " 'integrated into the  software development tools.  \\n• Moreover, given this stable, common development platform,  there is huge scope for design reuse.  \\n \\n• Intellectual Property (IP) functional blocks (corre sponding to the peripheral components ) can be \\nsourced from Xilin x libraries , reused from previous projects, or brought in  from third parties or open -\\nsource  repositories, before being integrated together to form the  system design.  \\n \\n• Zynq is an SoC, and a wide variety of standard IP is available, meaning that there is no  need to \\nredesign these components . \\n• By raising the abstraction level in this way, and reusing  components , development can be  \\naccelerated , and costs can be lowered.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRaising the Abs tract ion Level:',\n",
              " '• By raising the abstraction level in this way, and reusing  components , development can be  \\naccelerated , and costs can be lowered.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRaising the Abs tract ion Level:  \\n \\n• The design processes can b e accele rated i f the designer can effectively create  systems with a lower \\nrequirement for explicit design input . \\n• In terms of FPGA and Zynq design, advances in High Level Synthesis (HLS) mean that  designers can \\ncreate system components by specifying them using less detail than traditional  RTL methods . \\n• They can instead rely upon the design tools to  infer logic and optimi ze where possible, in accordance \\nwith user -supplied direction.  \\n• The development tools  must therefore  be robust and  produce repeatable and reliable designs.',\n",
              " 'with user -supplied direction.  \\n• The development tools  must therefore  be robust and  produce repeatable and reliable designs.  \\n• To meet this need, Xilinx has introduced the  Vivado HLS tool, a high -level  synthesis development tool \\nwhich specifically targets Xilinx  devices.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSoC Design Flow:  \\n \\n• The basic  and advanced  stages in a  SoC design  flow (as applied to Zynq ) is sho wn below:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The first stage is to define the desired behavio rs of  the system, i.e. requirem ents specification .  \\no This is  depicted as the starting point at the top of the diagram . \\no It forms the basis of the system  design that is subsequently developed.',\n",
              " 'o This is  depicted as the starting point at the top of the diagram . \\no It forms the basis of the system  design that is subsequently developed.  \\n \\n• The Zynq architecture combines an ARM processor  (for software elements of the  system) with FPGA \\nfabric (predominantly for  hardware elements of the system ).  \\no A key element of the system design stage  is therefore to partition the intended functionality \\nappropriately between software and  hardware .  \\no And to define the interfaces between the two sections.  \\n \\n• Having partitioned the system, software and hardware development  can then progress in  parallel, \\nto a large extent.  \\no In terms of hardware development , the task is to identify the  necessary functional blocks to',\n",
              " 'to a large extent.  \\no In terms of hardware development , the task is to identify the  necessary functional blocks to \\nachieve the design, and to assemble them through  some combination of design reuse and \\nnew IP development and  make appropriate  connections between the blocks.  \\n \\no The software development aspect of the project can be realized  through developing custom \\ncode or by reusing pre -existing software.  \\n \\no Verification of both  software and hardware will be required, and this forms an integral and \\nimportant part of  the process.  \\n \\n• In system  integration and testing sta ge, the hardware and software elements of the system must be \\nintegrated according  to the interfaces defined at the specification stage .  \\no And further ‘whole system ’ testing  is carried out .',\n",
              " 'integrated according  to the interfaces defined at the specification stage .  \\no And further ‘whole system ’ testing  is carried out . \\n \\nThe Zynq Device:  \\n \\n• The PS and the  PL parts can be used independently or together . \\n• In fact, the power circuitry is configured with separate  domains for each, enabling either the PS or PL \\nto be powered down if not in use.  \\n• However,  the most compelling use model for Zynq is when both of its constituent parts are used in  \\nconjunction . \\n \\n• PS: Processing system, hard silicon cor e \\no Dual ARM Cortex -A9 processor . \\no Multiple peripherals . \\n \\n• PL: Programmable logic  \\no Shares the same 7 series programmable logic as  \\n▪ Artix -based devices: Z -7010 and Z -7020 .',\n",
              " 'o Dual ARM Cortex -A9 processor . \\no Multiple peripherals . \\n \\n• PL: Programmable logic  \\no Shares the same 7 series programmable logic as  \\n▪ Artix -based devices: Z -7010 and Z -7020 . \\n▪ Kintex -based devices: Z -7030 and Z -7045 . • How were FPGAs used in the past:  \\n \\n \\n \\n \\n \\n \\n \\n \\nThe Processing S ystem:  \\n \\n• All Zynq devices have the same basic architecture, and all of them contain  a dual -core ARM Cortex -\\nA9 processor  as the PS.  \\n• This is a ‘hard ’ processor i.e., it exists as a dedicated and optimi zed silicon element on the device.  \\n \\n• For comparison purposes, the alternative to a hard processor is a ‘soft’ processor like the  Xilinx \\nMicroBlaze, which is formed by combining elements of the programmable logic  fabric .',\n",
              " '• For comparison purposes, the alternative to a hard processor is a ‘soft’ processor like the  Xilinx \\nMicroBlaze, which is formed by combining elements of the programmable logic  fabric .  \\n• The implementation of a soft processor is therefore the equivalent of any other  IP block deployed in \\nthe logic fabric of an FPGA.  \\n• In general, the advantage of soft  processors  is that the number and precise implementation of \\nprocessor instances is flexible.  \\n \\n• On the other hand, hard processors can achieve considerably higher performance . \\n• One or more MicroBlaze soft processors can be used within the PL  portion of the Zynq, to operate in \\nconjunction with the ARM processor.  \\n• The MicroBlaze  instances may have, for example,',\n",
              " '• One or more MicroBlaze soft processors can be used within the PL  portion of the Zynq, to operate in \\nconjunction with the ARM processor.  \\n• The MicroBlaze  instances may have, for example,  \\no the role of co ordinating specific low -level functions  within the system , \\no or less demanding tasks which can be delegated away from the main ARM  Cortex -A9 \\nprocessors to enhance overall performance.  \\n \\n• In other words, the presence of the  ARM processor in the system does not prevent  the use of soft \\nprocessors .  \\no Many applications may benefit from employing a processing model  which uses  both types.  \\n \\n• The figure b elow  confirms the positions of the ARM and MicroBlaze processors on the Zynq  device;',\n",
              " 'o Many applications may benefit from employing a processing model  which uses  both types.  \\n \\n• The figure b elow  confirms the positions of the ARM and MicroBlaze processors on the Zynq  device; \\nthe ARM as a dedicated resource, and the MicroBlaze located in the logic fabric.  \\n \\n \\n \\n \\n• The Zynq PS encompasses not just the ARM processor, but a  set of associated processing \\nresources /com ponent s: \\no Application Processing Unit (APU),  \\no I/O peripheral interfaces,  \\n▪ Multiplexed I/ O (MIO)  \\n▪ Extended Multiplexed I/O (EM IO)  \\no Cache memory,  \\no On-Chip memory,  \\no Memory interfaces,  \\no PS interconnect,  \\no Clock, DMA, Timers,  \\no General Interrupt Controller (GIC) , \\no Debug C ontroller: ARM CoreSight',\n",
              " 'o Cache memory,  \\no On-Chip memory,  \\no Memory interfaces,  \\no PS interconnect,  \\no Clock, DMA, Timers,  \\no General Interrupt Controller (GIC) , \\no Debug C ontroller: ARM CoreSight   \\n \\n• A block diagram showing the architecture of the PS is shown in  where the APU is highlighted.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nApplication Proc essing Unit (APU):  \\n• A simplified block diagram of the APU is shown .  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The APU is primarily  comprised of two ARM processing cores, each with associated computational \\nunits:  \\no a NEONTM Media Processing Engine (MPE) and Floating -Point  Unit (FPU) ,  \\no a Memory  Management Unit (MMU) , and  \\no a Level 1 cache memory (in two sections for instructions  and data).',\n",
              " 'o a NEONTM Media Processing Engine (MPE) and Floating -Point  Unit (FPU) ,  \\no a Memory  Management Unit (MMU) , and  \\no a Level 1 cache memory (in two sections for instructions  and data).  \\n \\n• The APU also contains a Level 2 cache memory, and a further On -Chip Memory  (OCM).  \\n• Finally, a Snoop Control Unit (SCU) forms a bridge between the ARM cores and  the Level 2 cache and \\nOCM memories . \\no This unit also has some responsibility for interfacing  with the PL . \\n \\n• The ARM Cortex -A9 can operate at up to 1GHz .  \\n• Each of the two cores has separate Level 1  caches for  data and instructions, both of which are 32KB ; \\nas in the general case, this allows for  local  storage of frequently required data and instructions for \\nfast access times and optimal  processor performance.',\n",
              " 'as in the general case, this allows for  local  storage of frequently required data and instructions for \\nfast access times and optimal  processor performance.  \\n• The two cores additionally share a larger Level 2  cache of 512KB  for instructions and data, and there \\nis a further 256KB of on -chip memory  within the APU.  \\n• The primary role of the MMU  is to translate between virtual and physical addresses . \\n \\n• The Snoop Control Unit  undertakes several tasks relating to interfacing between the  processors and \\nLevel 1 and 2 cache memories  (‘snooping ’ is one of several ways  for ensuring cache  coherency ).  \\n• The SCU is  responsible for maintaining memory coherency between the  processor data cache \\nmemories, which are marked as L1(D) , and the shared  Level 2 cache memory.',\n",
              " '• The SCU is  responsible for maintaining memory coherency between the  processor data cache \\nmemories, which are marked as L1(D) , and the shared  Level 2 cache memory.  \\n• It also initiates and controls access to the Level 2 cache, arbitrating  between requests from the two \\ncores where necessary .  \\n \\n• Timers and an interrupt controller are further functional blocks  located in the APU . \\n \\n• As additional functionality to the main ARM processor, the NEON engine  provides  SIMD  facilities to \\nenable strategic acceleration of media  and DSP type algorithms .  \\n• NEON instructions are an extension to the standard ARM  instruction set, and can either be used \\nexplicitly, or by ensuring that the C code follows an  expected form and thus allows NEON operations',\n",
              " '• NEON instructions are an extension to the standard ARM  instruction set, and can either be used \\nexplicitly, or by ensuring that the C code follows an  expected form and thus allows NEON operations \\nto be inferred by the compiler .  \\n \\n• As the SIMD term suggests, the NEON engine can accept multiple sets of input vectors, upon  which \\nthe same operation is performed simultaneously to provide a corresponding set of  output vectors.  \\n• This style of computation caters well to applications like \\no image and video  processing, which operate on a large number of data samples (pixels) \\nsimultaneously, and   \\no inherently parallel, generic signal processing functions such as FIR filters and FFTs . \\n \\n• The computation of the NEON engine is depicted in the figure below .',\n",
              " 'o inherently parallel, generic signal processing functions such as FIR filters and FFTs . \\n \\n• The computation of the NEON engine is depicted in the figure below .  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• There are two input  registers, A and B, each of which contain a set of N individual input vectors.  \\n• A single  defined operation  is performed between the N sets of input vectors to produce a \\ncorre sponding set of output vectors which are written to the output register.  \\n• The size of the  vectors can vary, as can the number of vectors comprising each register . \\n• The important  feature is that each ‘lane ’ produces results arising from the same operation, which is  \\nperformed on several different sets of inputs at the same time , hence the term SIMD.',\n",
              " '• The important  feature is that each ‘lane ’ produces results arising from the same operation, which is  \\nperformed on several different sets of inputs at the same time , hence the term SIMD.  \\n \\n• NEON supports a variety of data types including signed and unsigned integers, single  precision \\nfloating point, and half -precision floating point; however, double precision is not  supported .  \\n• The FPU (which does not possess SIMD capabilities) is  required if double precision computation is \\nneeded.  \\n \\n• In addition to NEON, there are also extensions for the FPU referred to as ‘Floating Point Extensions ’, \\nor sometimes ‘VFP Extensions ’ (Vecto r Floating Point) for historical reasons.  \\n• The unit provides hardware acceleration of floating -point operations .',\n",
              " 'or sometimes ‘VFP Extensions ’ (Vecto r Floating Point) for historical reasons.  \\n• The unit provides hardware acceleration of floating -point operations . \\nProcessing S ystem Extern al Interfaces:  \\n \\nThe Zynq PS features a variety of interfaces,  \\nboth between the PS and PL, and  \\nbetween  the PS and external components .  \\n \\n \\n \\n \\n \\n• Communication between the PS and external interfaces is achieved primarily via the  Multiplexed \\nInput/Output (MIO) , which provides 54 pins of flexible connectivity, meaning  that the mapping \\nbetween peripherals and pins can be defined as required.  \\n• Certain connec tions can also be made via the Extended MIO (EMIO) , which is not a direct path from \\nthe PS to external connections, but instead passes through and shares the I/O resources of the  PL.',\n",
              " 'the PS to external connections, but instead passes through and shares the I/O resources of the  PL.  \\n \\n• The EMIO can be used  when extension beyond 54 pins is required, or as a method of int erfacing the \\nPS with an I P block implemented in the PL.  \\n• The available I/O includes standard communications interfaces, and GPIO  which can be used for a \\nvariety of purposes including simple  buttons, switches, and LEDs.  \\n• The complete set of I/O peripheral interfaces is reviewed in  the t able below, there are two instances \\nof each type of communications interface.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPS Compo nents:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nProg rammable Logi c: \\n \\n• The programmable logic of t he Z ynq architecture is based on the Artix -7 and Kintex -7 FPGA fabric . \\n \\nThe Logic Fabric:',\n",
              " 'PS Compo nents:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nProg rammable Logi c: \\n \\n• The programmable logic of t he Z ynq architecture is based on the Artix -7 and Kintex -7 FPGA fabric . \\n \\nThe Logic Fabric:  \\n \\n• The PL is predominantly composed of general -purpose FPGA logic fabric,  which is composed of slices \\nand CLBs , and there are also Input/ Output Blocks (IOBs) for interfacing.  \\n• Configurable Logic Block (CLB) : CLBs are small, regular groupings of logic  elements that are laid out \\nin a two -dimensional array on the PL . \\no They are  connected  to other similar resources via programmable interconnects.  \\no Each CLB is positioned  next to a switch matrix and contains two logic slices .',\n",
              " 'o They are  connected  to other similar resources via programmable interconnects.  \\no Each CLB is positioned  next to a switch matrix and contains two logic slices . \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• Slice : A sub -unit within the CLB, which contains resources for implementing  combinatorial and \\nsequential logic circuits.  \\no Zynq slices  are composed of 4 Lookup Tables, 8 Flip -Flops, and other logic.  \\n \\n• Lookup Table (LUT) : A flexible resource capable of implementing  \\no a logic  function of up to six inputs ,  \\no a small Read Only Memory (ROM) ,  \\no a small  Random Access Memory (RAM) , or  \\no a shift register.  \\no LUTs can be combined  together to form larger logic functions, memories, or shift registers, as \\nrequired.',\n",
              " 'o a small  Random Access Memory (RAM) , or  \\no a shift register.  \\no LUTs can be combined  together to form larger logic functions, memories, or shift registers, as \\nrequired.  \\n \\n• Flip-flop (FF) : A sequential circuit element implementing a 1 -bit register, with  reset functionality.  \\no One of the FFs can optionally be used to implement a latch.  \\n \\n• Switch Matrix : A switch matrix sits next to each CLB, and provides a flexible  routing facility for \\nmaking connection s \\no between elements within a CLB  and  \\no from one CLB to other resources on the PL.  \\n \\n• Carry logic : Arithmetic circuits require intermediate signals to be propagated  between adjacent \\nslices, and this is achieved via carry logic.',\n",
              " 'o from one CLB to other resources on the PL.  \\n \\n• Carry logic : Arithmetic circuits require intermediate signals to be propagated  between adjacent \\nslices, and this is achieved via carry logic.  \\no It comprises a chain of routes and multiplexers to link slices in a vertical column.  \\n \\n• Input /Output Blocks (IOBs) : IOBs are resources that provide interfacing betwee n the PL logic \\nresources, and the physical device ‘pads ’ used to connect to external  circuitry.  \\no Each IOB can handle a 1 -bit input or output signal.  \\no IOBs are usually  located around the perimeter of the device.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The Xilinx tools  automatically infer the required LUTs, FFs, IOBs etc. from the design, and  map s them \\naccordingly.  \\n \\nSpecial Resources: DSP48E1s and BRAMs',\n",
              " '• The Xilinx tools  automatically infer the required LUTs, FFs, IOBs etc. from the design, and  map s them \\naccordingly.  \\n \\nSpecial Resources: DSP48E1s and BRAMs  \\n \\n• In addition to the general fabric, there are two special purpose components: B RAMs for dense \\nmemory requirements; and DSP48E1 slices for high -speed arithmetic.   \\n• Both of these resources are integrated into the logic array in a column arrangement,  embedded into \\nthe fabric logic . \\n• They are normally in close proximity to each other (the reason being  that intensive computation  – \\nDSP and storage of data in memory – BRAM are often closely associated  operations).  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The B RAMs in the Zynq -7000 are equivalent to those on Xilinx 7 series FPGAs,  and they can',\n",
              " 'DSP and storage of data in memory – BRAM are often closely associated  operations).  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• The B RAMs in the Zynq -7000 are equivalent to those on Xilinx 7 series FPGAs,  and they can \\nimplement RAM, ROM, FIF O buffers, while also supporting Error Correction Coding  (ECC) . \\n• Each B RAM can store up to 36Kb  of information, and may be configured either as  one 36Kb  RAM, or \\ntwo independent 18Kb RAMs .  \\no The default word size is 18 bits, and in  this configuration each RAM comprises 2048 memory \\nelements. (2 x 2^10 = 2048)  \\no The RAM can also be  ‘reshaped ’ such that it contains more, smaller elements (for example \\n4096 elements x 9 bits,  or 8192 x 4 bits), or alternatively, fewer, longer elements (e.g. 1024 \\nelements x 36 bits, 512 x  72 bits).',\n",
              " '4096 elements x 9 bits,  or 8192 x 4 bits), or alternatively, fewer, longer elements (e.g. 1024 \\nelements x 36 bits, 512 x  72 bits).  \\no Larger capacity memories can be formed by combining two or more Block RAMs  together.  \\n \\n• Using a B RAM means that a large amount of data can be stored in a small physical  space on the \\ndevice, within a dedicated and optimi zed memory element . \\n• The alternative is  Distributed RAM, which is constructed from the LUTs within the logic fabric.  \\n• A significant  number of LUTs (spanned over a larger area) are required to form a memory of \\ncomparable  size to a B RAM, and the resulting implementation suffers from restricted timing  \\nperformance due to the increased logic and routing delays.',\n",
              " 'comparable  size to a B RAM, and the resulting implementation suffers from restricted timing  \\nperformance due to the increased logic and routing delays.  \\n• On the other hand, it is often  advantageous  to implement small memories using Distributed RAM, \\nboth for resource  efficiency, and because their placement is more flexible . \\no Distributed memories can be  located close to the components that interact with them, \\nwhich can result in fast timing  performance too .  \\n• BRAMs can normally be clocked at the highest clock frequency  supported by the device.  \\n \\n• The LUTs in the logic fabric can be used to implement arithmetic operators of any  arbitrary length \\nbut are most suitable for arithmetic operators with short word lengths .',\n",
              " '• The LUTs in the logic fabric can be used to implement arithmetic operators of any  arbitrary length \\nbut are most suitable for arithmetic operators with short word lengths . \\no Arithmetic circuits for long word  lengths can have a large footprint in slice logic, with  \\nplacement and routing factors resulting in sub -optimal clock frequencies .  \\n \\n• DSP48E1s  are specialist slices for implementing high -speed arithmetic on signals with medium to \\nlong  arithmetic word  lengths.  \\n• They are dedicated silicon resources, and primarily comprise a  pre-adder/subtractor, multiplier, and \\npost -adder/subtractor with logic unit .  \\n \\n \\n \\n \\n \\n \\n \\n \\n• DSP48E1 makes use of multiplexing circuitry to allow  flexible usage of registers, and to  support',\n",
              " 'post -adder/subtractor with logic unit .  \\n \\n \\n \\n \\n \\n \\n \\n \\n• DSP48E1 makes use of multiplexing circuitry to allow  flexible usage of registers, and to  support \\ndynamic alteration of the computation (i.e. the function can be changed on a cycle -by-cycle basis as \\nrequired).  \\n• Various computations are possible, involving one, two or all of  these arithmetic operators, and these \\nare selected via an OPMODE input  that configures  the internal multiplexers and determines the \\narithmetic  functionality implemented.  \\no Notice that the inputs are labelled A, B, C, and D, and that the  output is labelled P .  \\no The unit can compute the functions P = (A+D)*B, or P = P ’ + C, or in  fact many others.  \\no It is also capable of SIMD processing, implementing 2 or 4 shorte r',\n",
              " 'o The unit can compute the functions P = (A+D)*B, or P = P ’ + C, or in  fact many others.  \\no It is also capable of SIMD processing, implementing 2 or 4 shorte r \\naddition/subtraction/accumulation operations of 24 or 12 bits, respectively.  \\n \\n• The post -adder  has additional capabilities as a logic unit.   \\n• When used in logic mode, it can perform logical functions instead of arithmetic, and  supports all of \\nthe fundamental Boolean  operations: bit -wise NOT, AND, OR, NAND,  NOR , XOR, and XNOR.  \\n \\n• It is also worth mentioning the pattern detector  which adds the capability to detect overflow, \\nperform rounding according to a  selection of schemes  and undertake other related functions.',\n",
              " '• It is also worth mentioning the pattern detector  which adds the capability to detect overflow, \\nperform rounding according to a  selection of schemes  and undertake other related functions.  \\n \\n• The standard arithmetic word  lengths marked on the figure  are adequate for most  requirements, but \\nthey can also be extended by combining multiple DSP48E1s, if needed.  \\n• Complex arithmetic can be undertaken, again by combining DSP48E1s, and the  word  lengths are also \\nsuitable for implementing floating -point arithmetic.  \\n \\n• Together with the  advantage of high frequency operation (just like B RAMs, DSP48E1s can be clocked \\nat the maximum clock frequency of the device) and low power consumption, these DSP48E1  slices',\n",
              " '• Together with the  advantage of high frequency operation (just like B RAMs, DSP48E1s can be clocked \\nat the maximum clock frequency of the device) and low power consumption, these DSP48E1  slices \\nare attractive for implementing computationally demanding arithmetic circuits.  \\n \\n• As a result of these properties, DSP48E1s are suited to a variety of applications in signal  processing \\nand beyond.  \\no One of their most compelling uses is to implement symmetric  form F IR filters , which are \\ncommonly used in DSP and digital  communications.  \\no The pre -adder ensures that each DSP48E1 can implement two filter taps,  and entire filters \\ncan be formed by cascading DSP48E1s together, without the requirement  to utilize  any logic \\nfrom the general fabric.',\n",
              " 'can be formed by cascading DSP48E1s together, without the requirement  to utilize  any logic \\nfrom the general fabric.  \\no This provides a high performance, highly  efficient implementation for one of the \\nfundamentally important computations in DSP .  \\n \\n• When designing with Zynq, it makes sense to identify deterministic, computationally  parallel \\nfunctions and implement them in the PL section of the device, specifically  targeting DSP and B RAM \\nresources where possible.  \\n• In this way, the PL can be used to  accelerate algorithms residing in the PS.  \\no There are many conceivable examples where the  availability of PL directly adjacent to the \\nprocessor, and the opportunity to allocate certain  system functions to the PL, can bring',\n",
              " 'o There are many conceivable examples where the  availability of PL directly adjacent to the \\nprocessor, and the opportunity to allocate certain  system functions to the PL, can bring \\nsignificant benefits to the overall system implemen tation.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n PS – PL Interfaces:  \\n \\n• The key enabler in the integration of PS and PL  is the set of highly specified  AXI interconnects and \\ninterfaces forming the bridge between the two parts.  \\n• There are also  some other types of connections between the PS and PL, in particular EMIO.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe AXI Standards:  \\n \\n \\n \\n \\n \\n \\n \\n \\n• AXI stands for Advanced eXtensible Interface, and the current version is AXI4, which is  part of the \\nARM AMBA ® 3.0 open standard.',\n",
              " 'The AXI Standards:  \\n \\n \\n \\n \\n \\n \\n \\n \\n• AXI stands for Advanced eXtensible Interface, and the current version is AXI4, which is  part of the \\nARM AMBA ® 3.0 open standard.  \\n• Many devices and IP blocks produced by third  party manufacturers and developers are based on this \\nstandard.  \\n \\n• The AMBA standard was originally developed by ARM for use in microcontrollers, with  the first \\nversion being released in 1996.  \\n• Since then, the standard has been revised and  extended, and it is now described by ARM as “the de \\nfacto standard for on -chip communi cation ”.  \\n• The focus is now on System -on-Chip, including SoCs based on FPGAs or, in  the case of Zynq, a device \\nwhich includes FPGA fabric.',\n",
              " 'facto standard for on -chip communi cation ”.  \\n• The focus is now on System -on-Chip, including SoCs based on FPGAs or, in  the case of Zynq, a device \\nwhich includes FPGA fabric.  \\n• Xilinx contributed strongly  to defining AXI4 as an optimal interconnect technology for use within \\nFPGA architecture s. \\n• AXI buses can be used flexibly, and in the general sense are used to connect the processor(s)  and \\nother IP blocks in an embedded system.  \\n• There are three flavo rs of AXI4, each  of which represents a different bus protocol . \\n• The cho ice of AXI bus protocol for a particular connection depends on the desired properties of that \\nconnection.  \\n \\n• AXI4 [2] : For memory -mapped links and  providing the highest performance: an  address is supplied',\n",
              " 'connection.  \\n \\n• AXI4 [2] : For memory -mapped links and  providing the highest performance: an  address is supplied \\nfollowed by a data burst transfer of up to 256 data words (or ‘data  beats ’). \\n \\n• AXI4 -Lite [2] : A simplified link supporting only one data transfer per connection  (no bursts).  \\no It is also memory -mapped: in this case an address and single  data word are transferred.  \\n \\n• AXI4 -Stream [1] : For high -speed streaming data, supporting burst transfers of  unrestricted size.  \\no There is no address mechanism; this bus type is best suited to  direct data flow between \\nsource and destination (non -memory mapped) . \\n \\n• If a protocol is memory mapped , an address is specified within the  transaction issued by the master',\n",
              " 'source and destination (non -memory mapped) . \\n \\n• If a protocol is memory mapped , an address is specified within the  transaction issued by the master \\n(read or write), which corresponds to an address in the  system memory space.  \\no In the case of AXI4 -Lite, which supports a single data transfer per  transaction, data is then \\nwritten to, or read from, the specified address .  \\no In the case of AXI4  bursts, the address specified is for the first data word to be transferred, \\nand the slave must  then calculate the addresses for the data words that follow.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAXI Interconne cts and Interfaces:  \\n \\n• The primary interface between the PS and PL is via a set of nine AXI interfaces, each of  which is',\n",
              " 'AXI Interconne cts and Interfaces:  \\n \\n• The primary interface between the PS and PL is via a set of nine AXI interfaces, each of  which is \\ncomposed of multiple channels.  \\n• These make dedicated connections between the  PL, and interconnects within the PS . \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• Interconnect : An interconnect is effectively a switch which manages and directs  traffic between \\nattached AXI interfaces.  \\no There are several interconnects within the  PS, some which are directly interfaced to the PL , \\nand others which  are for internal use only.  \\no The connections between these interconnects are also  formed using AXI interfaces.']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ17kubrvb_S",
        "outputId": "f1a4f0e1-db54-4fcc-960e-65d69129f773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 50 headlines.\n"
          ]
        }
      ],
      "source": [
        "astra_vector_store.add_texts(texts[:50])\n",
        "print(\"Inserted %i headlines.\" % len(texts[:50]))\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVVYDZ_OvYGR",
        "outputId": "0a05b3b9-87e7-43c1-d973-4e4f51d20b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Enter your question (or type 'quit' to exit): What are the components involved in PS and PL\n",
            "\n",
            "QUESTION: \"What are the components involved in PS and PL\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER: \"The components involved in PS and PL are the dual-core ARM Cortex-A9 processor, programmable logic equivalent to an FPGA, integrated memory, a variety of peripherals, high-speed communications interfaces, and industry standard Advanced eXtensible Interface (AXI) connections.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   [0.9181] \"o Processing System (PS) formed around a dual -core ARM  Cortex -A9 processor, and   ...\"\n",
            "   [0.9181] \"o Processing System (PS) formed around a dual -core ARM  Cortex -A9 processor, and   ...\"\n",
            "   [0.9181] \"o Processing System (PS) formed around a dual -core ARM  Cortex -A9 processor, and   ...\"\n",
            "   [0.9181] \"o Processing System (PS) formed around a dual -core ARM  Cortex -A9 processor, and   ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): quit\n"
          ]
        }
      ],
      "source": [
        "first_question = True\n",
        "while True:\n",
        "  if first_question:\n",
        "    query_text = input(\"\\n Enter your question (or type 'quit' to exit): \").strip()\n",
        "  else:\n",
        "    query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "  if query_text.lower()=='quit':\n",
        "    break\n",
        "  if query_text == \"\":\n",
        "    continue\n",
        "\n",
        "  first_question = False\n",
        "\n",
        "  print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "  answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "  print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "  print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "  for doc, score in astra_vector_store.similarity_search_with_score(query_text,k=4):\n",
        "    print(\"   [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4a9UWJV-ikG_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
